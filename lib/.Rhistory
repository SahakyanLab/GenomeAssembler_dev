recall = sensitivity(y_hat, test_set$sex),
precision = precision(y_hat, test_set$sex))
})
guessing
map_df(probs, function(p){
y_hat <- sample(c("Male", "Female"), length(test_index),
replace = TRUE, prob=c(p, 1-p)) %>%
factor(levels = c("Female", "Male"))
list(method = "Guess",
recall = sensitivity(y_hat, test_set$sex),
precision = precision(y_hat, test_set$sex))
})
sapply(probs, function(p){
y_hat <- sample(c("Male", "Female"), length(test_index),
replace = TRUE, prob=c(p, 1-p)) %>%
factor(levels = c("Female", "Male"))
list(method = "Guess",
recall = sensitivity(y_hat, test_set$sex),
precision = precision(y_hat, test_set$sex))
})
msapply(probs, function(p){
y_hat <- sample(c("Male", "Female"), length(test_index),
replace = TRUE, prob=c(p, 1-p)) %>%
factor(levels = c("Female", "Male"))
list(method = "Guess",
recall = sensitivity(y_hat, test_set$sex),
precision = precision(y_hat, test_set$sex))
})
mapply(probs, function(p){
y_hat <- sample(c("Male", "Female"), length(test_index),
replace = TRUE, prob=c(p, 1-p)) %>%
factor(levels = c("Female", "Male"))
list(method = "Guess",
recall = sensitivity(y_hat, test_set$sex),
precision = precision(y_hat, test_set$sex))
})
sapply(probs, function(p){
y_hat <- sample(c("Male", "Female"), length(test_index),
replace = TRUE, prob=c(p, 1-p)) %>%
factor(levels = c("Female", "Male"))
list(method = "Guess",
recall = sensitivity(y_hat, test_set$sex),
precision = precision(y_hat, test_set$sex))
}, simplify = TRUE)
map_df(probs, function(p){
y_hat <- sample(c("Male", "Female"), length(test_index),
replace = TRUE, prob=c(p, 1-p)) %>%
factor(levels = c("Female", "Male"))
list(method = "Guess",
recall = sensitivity(y_hat, test_set$sex),
precision = precision(y_hat, test_set$sex))
})
height_cutoff <- map_df(cutoffs, function(x){
y_hat <- ifelse(test_set$height > x, "Male", "Female") %>%
factor(levels = c("Female", "Male"))
list(method = "Height cutoff",
recall = sensitivity(y_hat, test_set$sex),
precision = precision(y_hat, test_set$sex))
})
height_cutoff
y_hat <- ifelse(test_set$height > x, "Male", "Female") %>%
factor(levels = c("Female", "Male"))
y_hat
list(method = "Height cutoff",
recall = sensitivity(y_hat, test_set$sex),
precision = precision(y_hat, test_set$sex))
bind_rows(guessing, height_cutoff) %>%
ggplot(aes(recall, precision, color = method)) +
geom_line() +
geom_point()
# plot precision against recall
guessing <- map_df(probs, function(p){
y_hat <- sample(c("Male", "Female"), length(test_index),
replace = TRUE, prob=c(p, 1-p)) %>%
factor(levels = c("Female", "Male"))
list(method = "Guess",
recall = sensitivity(y_hat, test_set$sex),
precision = precision(y_hat, test_set$sex))
})
height_cutoff <- map_df(cutoffs, function(x){
y_hat <- ifelse(test_set$height > x, "Male", "Female") %>%
factor(levels = c("Female", "Male"))
list(method = "Height cutoff",
recall = sensitivity(y_hat, test_set$sex),
precision = precision(y_hat, test_set$sex))
})
bind_rows(guessing, height_cutoff) %>%
ggplot(aes(recall, precision, color = method)) +
geom_line() +
geom_point()
guessing <- map_df(probs, function(p){
y_hat <- sample(c("Male", "Female"), length(test_index), replace = TRUE,
prob=c(p, 1-p)) %>%
factor(levels = c("Male", "Female"))
list(method = "Guess",
recall = sensitivity(y_hat, relevel(test_set$sex, "Male", "Female")),
precision = precision(y_hat, relevel(test_set$sex, "Male", "Female")))
})
height_cutoff <- map_df(cutoffs, function(x){
y_hat <- ifelse(test_set$height > x, "Male", "Female") %>%
factor(levels = c("Male", "Female"))
list(method = "Height cutoff",
recall = sensitivity(y_hat, relevel(test_set$sex, "Male", "Female")),
precision = precision(y_hat, relevel(test_set$sex, "Male", "Female")))
})
bind_rows(guessing, height_cutoff) %>%
ggplot(aes(recall, precision, color = method)) +
geom_line() +
geom_point()
####################################################################################
library(dslabs)
library(dplyr)
library(lubridate)
####################################################################################
library(dslabs)
library(dplyr)
library(lubridate)
data(reported_heights)
dat <- mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1)) %>%
mutate(type = ifelse(day(date_time) == 25 & hour(date_time) == 8 &
between(minute(date_time), 15, 30), "inclass","online")) %>%
select(sex, type)
dat
reported_heights
head(reported_heights)
ymd_hms(reported_heights$time_stamp)
head(reported_heights)
dat <- mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1)) %>%
mutate(type = ifelse(day(date_time) == 25 & hour(date_time) == 8 &
between(minute(date_time), 15, 30), "inclass","online")) %>%
select(sex, type)
dat
dim(reported_heights)
mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1))
dat
mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1)) %>%
mutate(type = ifelse(day(date_time) == 25 & hour(date_time) == 8 &
between(minute(date_time), 15, 30), "inclass","online"))
class(mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1)) %>%
mutate(type = ifelse(day(date_time) == 25 & hour(date_time) == 8 &
between(minute(date_time), 15, 30), "inclass","online")))
mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1)) %>%
mutate(type = ifelse(day(date_time) == 25 & hour(date_time) == 8 &
between(minute(date_time), 15, 30), "inclass","online"))
dat <- mutate(reported_heights, date_time = ymd_hms(time_stamp)) %>%
filter(date_time >= make_date(2016, 01, 25) & date_time < make_date(2016, 02, 1)) %>%
mutate(type = ifelse(day(date_time) == 25 & hour(date_time) == 8 &
between(minute(date_time), 15, 30), "inclass","online")) %>%
select(sex, type)
dat
y <- factor(dat$sex, c("Female", "Male"))
y
x <- dat$type
x
dat
which(dat$type=="inclass")
dat[which(dat$type=="inclass"),]
dim(dat[which(dat$type=="inclass"),])
dat$sex[which(dat$type=="inclass")]
dat$sex[which(dat$type=="inclass")]=="Female"
which(dat$sex[which(dat$type=="inclass")]=="Female")
length(which(dat$sex[which(dat$type=="inclass")]=="Female"))
26/39
length(which(dat$sex[which(dat$type=="online")]=="Female"))
dim(dat[which(dat$type=="online"),])
42/111
x
x
y
# examine the accuracy of 10 cutoffs
cutoff <- seq(61, 70)
accuracy <- map_dbl(cutoff, function(x){
y_hat <- ifelse(train_set$height > x, "Male", "Female") %>%
factor(levels = levels(test_set$sex))
mean(y_hat == train_set$sex)
})
accuracy
dat %>% filter(type == 'online' & sex == 'Female')
# compute proportion of women in online and inclass types
dat %>% filter(type == 'online' & sex == 'Female') %>% nrow
# Question 1 #
# compute proportion of women in online and inclass types
which(dat$sex[which(dat$type=="inclass")]=="Female")
# Question 1 #
# compute proportion of women in online and inclass types
dat %>% filter(type == "online" & sex == "Female")
# Question 1 #
# compute proportion of women in online and inclass types
dat %>% filter(type == "online" & sex == "Female") %>% nrow
# Question 1 #
# compute proportion of women in online and inclass types
dat %>% filter(type == "online" & sex == "Female") %>% nrow / 100
# Question 1 #
# compute proportion of women in online and inclass types
dat %>% filter(type == "online" & sex == "Female") %>% nrow /
100
# Question 1 #
# compute proportion of women in online and inclass types
dat %>% filter(type == "online" & sex == "Female") %>% nrow /
dat %>% filter(type == "online")
# Question 1 #
# compute proportion of women in online and inclass types
dat %>% filter(type == "online" & sex == "Female") %>% nrow /
(dat %>% filter(type == "online"))
dat %>% filter(type == "online")
# Question 1 #
# compute proportion of women in online and inclass types
dat %>% filter(type == "online" & sex == "Female") %>% nrow /
dat %>% filter(type == "online") %>% nrow
# Question 1 #
# compute proportion of women in online and inclass types
dat %>% filter(type == "inclass" & sex == "Female") %>% nrow /
dat %>% filter(type == "inclass") %>% nrow
# Question 2 #
# Report the accuracy of your prediction of sex based on type
ifelse(x == "inclass", "Female", "Male") %>% factor()
# Question 2 #
# Report the accuracy of your prediction of sex based on type
y_hat <- ifelse(x == "inclass", "Female", "Male") %>% factor()
y_hat
y
mean(y == y_hat)
mean(y_hat == y)
mean(y == y_hat)
dat %>% group_by(type) %>% summarize(prop_female = mean(sex == "Female"))
dat %>% group_by(type)
# Question 2 #
# Report the accuracy of your prediction of sex based on type
y_hat <- ifelse(x == "inclass", "Female", "Male") %>%
factor(levels = levels(y))
mean(y_hat == y)
# Question 3 #
# Write a line of code using the table() function to show the confusion matrix between y_hat and y
table(predicted = y_hat, actual = x)
# Question 3 #
# Write a line of code using the table() function to show the confusion matrix between y_hat and y
table(predicted = y_hat, actual = x)
confusionMatrix(data = y_hat, reference = x)
y_hat
x
y
# Question 3 #
# Write a line of code using the table() function to show the confusion matrix between y_hat and y
table(predicted = y_hat, actual = y)
confusionMatrix(data = y_hat, reference = y)
y
factor(dat$sex)
confusionMatrix(data = y_hat, reference = y)
# Question 3 #
# Write a line of code using the table() function to show the confusion matrix between y_hat and y
table(y_hat, y)
# Question 4 #
# What is the sensitivity of this prediction? You can use the sensitivity() function from the caret package.
sensitivity(data = y_hat, reference = y)
# Question 5 #
# What is the specificity of this prediction?
specificity(data = y_hat, reference = y)
# Question 2 #
# Report the accuracy of your prediction of sex based on type
y_hat <- ifelse(x == "online", "Female", "Male") %>%
factor(levels = levels(y))
mean(y_hat == y)
# Question 2 #
# Report the accuracy of your prediction of sex based on type
y_hat <- ifelse(x == "inclass", "Female", "Male") %>%
factor(levels = levels(y))
mean(y_hat == y)
# Question 6 #
# What is the prevalence (% of females) in the dat dataset defined above?
confusionMatrix(data = y_hat, reference = y)
packages <- function(x){
for(i in x){
if(!require(i, character.only = TRUE)){
install.packages(i, dependencies = TRUE)
library(i, character.only = TRUE)
} else {
library(i, character.only = TRUE)
}
}
}
suppressMessages(packages(c("foreach", "doSNOW", "ggExtra", "ggplot2",
"cowplot", "stringr", "doRNG", "dplyr", "tidyr", "doParallel", "itertools")))
breakage.prob.scoring <- function(randSeq, output, len, seed){
set.seed(seed)
if(length(output)==0){
# if DBG assembly took too long, it will stop at X-minutes, where X is
# the upper time limit for exploration; in such a case, it will generate
# no assembled result, hence no pathway obtained and we return NULL
return()
} else {
# import all generatd reads
reads <- scan("../data/reads.txt", what = character(), sep = "", quiet = TRUE)
# create copy of probability reference table to be reset in each iteration
prob.ref.copy <- randSeq
# initialise vector to store the sums of breakpoint probability occurrences
prob.ref.sums <- vector(mode = "numeric", length = length(output))
prob.ref.seq  <- vector(mode = "numeric", length = length(output))
pb <- txtProgressBar(min = 1, max = length(output), style = 3)
sums.index = 1
print("Counting k-mer breakpoints...", quote = F)
for(path in 1:length(output)){
prob.ref <- prob.ref.copy
# counter column for number of occurrence of k-mer breakages
prob.ref$freq <- 0
out.put <- strsplit(output[[path]], split = "")[[1]]
for(i in 1:length(reads)){
read.result <- gregexpr(pattern = reads[i], output[[path]], perl=TRUE)
read.start  <- read.result[[1]][1]
if(read.start!=(-1)){
# extract attributes from read and reference sequence overlap
read.length <- attr(read.result[[1]], 'match.length')
read.end    <- read.start+read.length-1
# obtain the k-mers that are broken on either end of the read
if(read.start==1){
# if k-mer is at the start of the genome
kmer.start <- paste(out.put[read.start:(read.start+1)], collapse = "")
} else {
kmer.start <- paste(out.put[(read.start-1):read.start], collapse = "")
}
if(length(out.put)==read.end){
# if k-mer is at the end of the genome
kmer.end <- paste(out.put[(read.end-1):read.end], collapse = "")
} else {
kmer.end <- paste(out.put[read.end:(read.end+1)], collapse = "")
}
# obtain index of the above k-mers
start.ind <- match(kmer.start, prob.ref$fwd.kmer)
end.ind   <- match(kmer.end, prob.ref$fwd.kmer)
# increase counter of given k-mer occurrence in data frame
prob.ref$freq[start.ind] <- prob.ref$freq[start.ind]+1
prob.ref$freq[end.ind]   <- prob.ref$freq[end.ind]+1
}
if(i==length(reads)){
prob.ref.sums[sums.index] <- sum(prob.ref$prob*prob.ref$freq)
prob.ref.seq[sums.index]  <- nchar(output[[path]])
sums.index = sums.index+1
}
}
setTxtProgressBar(pb, path)
}
close(pb)
# omit any zero probability outcomes as will falsely skew the final result
# ind <- which(prob.ref.sums==0)
# if(length(ind)>0){
#   prob.ref.sums <- prob.ref.sums[-ind]
#   prob.ref.seq  <- prob.ref.seq[-ind]
#   output        <- output[-ind]
# }
# only accept the top 50% of the de novo assembled solutions
ind           <- which(prob.ref.seq>=len*0.5)
prob.ref.sums <- prob.ref.sums[ind]
prob.ref.seq  <- prob.ref.seq[ind]
output        <- output[ind]
# normalising the score to ignore the effect of seq length on total score
prob.ref.sums <- prob.ref.sums/prob.ref.seq
print("All k-mer breakpoints counted!", quote = F)
sorted.sums <- match(sort(prob.ref.sums, decreasing = TRUE), prob.ref.sums)
return(list(output[sorted.sums[1]][[1]], prob.ref.sums, prob.ref.seq, output))
}
}
####################################################################################
setwd("/Volumes/Paddy_Backup/ProjectBoard_Patrick/02-Proof_of_principle/lib/")
source("../lib/ReadsGenerator.R")
source("../lib/DeBruijnGraph.R")
source("../lib/AlignmentScoring.R")
comb <- function(x, ...) {
lapply(seq_along(x),
function(i) c(x[[i]], lapply(list(...), function(y) y[[i]])))
}
####################################################################################
cl <- makeCluster(4)
registerDoParallel(cl)
# Declare that parallel RNG should be used for in a parallel foreach() call.
# %dorng% will still result in parallel processing; uses %dopar% internally.
registerDoRNG(seed = 1234)
out.put <- foreach(i=1:8,
.export=ls(globalenv()),
.combine="rbind"
# .packages=c("foreach"),
# .combine="comb", .multicombine = TRUE,
# .init = list(list(), list())
)%dopar%{
randSeq <- ReadsGenerator(len = 1000, G.cont = 0.25, C.cont = 0.25,
A.cont = 0.25, NCPU = 4,
length.of.read = 100,
multiplier = 53,
prob.type = "non-uniform", seed = 1234, k = 9)
# reads  <- randSeq[[8]]
# kmers  <- randSeq[[8]]
# output <- kmer.composition(k = 9, seed = 1234)
# output <- output[[1]]
output <- eulerian.path(get.balance.count(
debrujin.graph.from.kmers(randSeq[[7]])), timer = 1)
breakage.output <- breakage.prob.scoring(randSeq[[2]], output, len = 1000, seed = 1234)
#
align <- alignment.scoring(path = breakage.output[[4]], randSeq[[1]], NCPU = 4, seed = 1234)
# df  <- data.frame(out = reads)
df <- data.frame(probs  = breakage.output[[2]],
scores = align[[2]])
# df2 <- data.frame(scores = align[[2]])
return(df)
# return(list(df, df2))
# return(list(df, df1, df2))
}
stopCluster(cl)
seq1 <- out.put[[1]]
seq1
cl <- makeCluster(4)
registerDoParallel(cl)
# Declare that parallel RNG should be used for in a parallel foreach() call.
# %dorng% will still result in parallel processing; uses %dopar% internally.
registerDoRNG(seed = 1234)
out.put <- foreach(i=1:8,
.export=ls(globalenv()),
.combine="rbind"
# .packages=c("foreach"),
# .combine="comb", .multicombine = TRUE,
# .init = list(list(), list())
)%dopar%{
randSeq <- ReadsGenerator(len = 1000, G.cont = 0.25, C.cont = 0.25,
A.cont = 0.25, NCPU = 4,
length.of.read = 100,
multiplier = 53,
prob.type = "non-uniform", seed = 1234, k = 9)
# reads  <- randSeq[[8]]
# kmers  <- randSeq[[8]]
# output <- kmer.composition(k = 9, seed = 1234)
# output <- output[[1]]
output <- eulerian.path(get.balance.count(
debrujin.graph.from.kmers(randSeq[[7]])), timer = 1)
breakage.output <- breakage.prob.scoring(randSeq[[2]], output, len = 1000, seed = 1234)
#
align <- alignment.scoring(path = breakage.output[[4]], randSeq[[1]], NCPU = 4, seed = 1234)
# df  <- data.frame(out = reads)
df <- data.frame(probs  = breakage.output[[2]],
scores = align[[2]])
# df2 <- data.frame(scores = align[[2]])
return(df)
# return(list(df, df2))
# return(list(df, df1, df2))
}
stopCluster(cl)
seq2 <- out.put[[1]]
identical(seq1,seq2)
string.reconstruction <- function(len = len, G.cont = G.cont,
C.cont = C.cont, A.cont = A.cont,
k = k, NCPU = NCPU,
timer = timer, # max.time per DBG assembly
length.of.read = length.of.read, # length of each read
multiplier = multiplier, # read generation number multiplier
prob.type = prob.type, # "uniform" or "non-uniform"
# ind = i,
seed = seed
){
# measure execution time
start.time <- Sys.time()
# generate random genome sequence
randSeq <- ReadsGenerator(len = len, G.cont = G.cont, C.cont = C.cont,
A.cont = A.cont, k.mer = 2, NCPU = NCPU,
length.of.read = length.of.read,
multiplier = multiplier,
prob.type = prob.type,
# ind = i,
k = k, seed = seed)
# traverse all paths in the rooted tree and construct the Eulerian paths
output <- eulerian.path(get.balance.count(
debrujin.graph.from.kmers(randSeq[[7]])), timer = 1)
# obtain most plausible sequence based on breakage probability scores
breakage.output <- breakage.prob.scoring(randSeq[[2]], output, len = len, seed = 1234)
# calculate the alignment scores per reconstructed genome vs. reference sequence
align <- alignment.scoring(path = breakage.output[[4]], randSeq[[1]], NCPU = NCPU, seed = 1234)
# measure execution time
end.time   <- Sys.time()
time.taken <- end.time-start.time
RESULTS                   <- NULL
RESULTS$ref.seq           <- paste(randSeq[[1]], collapse = "") # reference sequence
RESULTS$alignment.seq     <- align[[1]] # highest-score assembled sequence
RESULTS$alignment.scores  <- align[[2]] # all calculated alignment scores
RESULTS$alignment.res     <- align[[3]] # all calculated alignment scores in a df
RESULTS$breakage.best.seq <- breakage.output[[1]] # highest breakage prob score sequence
RESULTS$prob.ref.table    <- breakage.output[[2]] # all breakage probability scores
RESULTS$prob.ref.seq      <- breakage.output[[3]] # all assembled sequence lengths
RESULTS$prob.table        <- randSeq[[2]] # table of probs to bias reads generation
RESULTS$kmer.prob.seq     <- randSeq[[6]] # all k-mers from genome and associated probs
RESULTS$total.reads       <- randSeq[[3]] # total number of reads generated
RESULTS$reads.freq        <- unlist(randSeq[[5]]) # read positions in the genome
RESULTS$coverage          <- randSeq[[4]] # total coverage
RESULTS$execution.time    <- time.taken   # execution time to run all functions
return(RESULTS)
}
results <- string.reconstruction(len = 1000, G.cont = 0.25,
C.cont = 0.25, A.cont = 0.25,
k = 9, NCPU = 4,
timer = 1,
length.of.read = 100,
multiplier = 53,
prob.type = "non-uniform",
seed = 1234)
results <- string.reconstruction(len = 1000, G.cont = 0.25,
C.cont = 0.25, A.cont = 0.25,
k = 9, NCPU = 4,
timer = 1,
length.of.read = 100,
multiplier = 53,
prob.type = "non-uniform",
seed = 1234)
